{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM9fNF3ggaXhyLK2VjM/Tbb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karath-Vamsi/NLP-basics/blob/main/Word_embedding_using_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExGuZUkHqf2t",
        "outputId": "afe830ec-278d-45c6-c04e-46a4df0428b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3sS0eBiq0xy",
        "outputId": "d1ed74ee-da9a-4d92-eccb-a1553d17097d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot"
      ],
      "metadata": {
        "id": "IcqFf4Iwq4LJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ],
      "metadata": {
        "id": "WXbsWvSdq4vn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "voc_size=1000\n",
        "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OcpiGr8rB_g",
        "outputId": "b8915341-d40f-488d-8c04-2640eeb4f57b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[680, 834, 273, 350], [680, 834, 273, 459], [680, 659, 273, 602], [291, 733, 180, 895, 516], [291, 733, 180, 895, 203], [982, 680, 796, 273, 539], [338, 392, 513, 895]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ra0fmPFKrHwT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "sent_length=8\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2cIS9NcrKOF",
        "outputId": "e4b9033a-497b-4cae-f09c-b5e6c797a8a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0 680 834 273 350]\n",
            " [  0   0   0   0 680 834 273 459]\n",
            " [  0   0   0   0 680 659 273 602]\n",
            " [  0   0   0 291 733 180 895 516]\n",
            " [  0   0   0 291 733 180 895 203]\n",
            " [  0   0   0 982 680 796 273 539]\n",
            " [  0   0   0   0 338 392 513 895]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an embedding layer\n",
        "dim = 10\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmtzhsLZrT8R",
        "outputId": "0840f2f9-a38e-44ac-8636-87566aa1d78f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1gV9MDprh49",
        "outputId": "9ac1359c-8426-4fe2-ddee-d835953be627"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02239746, -0.01824399, -0.01177598,  0.00277194,  0.01039684,\n",
              "        -0.03914303,  0.04672184, -0.02488312, -0.01910791,  0.02675634],\n",
              "       [-0.02239746, -0.01824399, -0.01177598,  0.00277194,  0.01039684,\n",
              "        -0.03914303,  0.04672184, -0.02488312, -0.01910791,  0.02675634],\n",
              "       [-0.02239746, -0.01824399, -0.01177598,  0.00277194,  0.01039684,\n",
              "        -0.03914303,  0.04672184, -0.02488312, -0.01910791,  0.02675634],\n",
              "       [-0.02239746, -0.01824399, -0.01177598,  0.00277194,  0.01039684,\n",
              "        -0.03914303,  0.04672184, -0.02488312, -0.01910791,  0.02675634],\n",
              "       [-0.03334149,  0.02823806, -0.03048906,  0.02215946, -0.01486676,\n",
              "        -0.03543171, -0.01871197, -0.01990491, -0.03002671,  0.0058069 ],\n",
              "       [-0.01905068,  0.00099443, -0.03801687,  0.01511199, -0.01964667,\n",
              "        -0.03668207,  0.02761669, -0.04150029,  0.023764  , -0.00189922],\n",
              "       [-0.01912125, -0.03021339,  0.01742405, -0.03340002,  0.04789079,\n",
              "        -0.00620224,  0.04393006,  0.00404038,  0.01547862,  0.00320949],\n",
              "       [-0.02564855, -0.00823784, -0.0418533 ,  0.01919961,  0.04497394,\n",
              "        -0.01024874,  0.01774689,  0.02353419, -0.0469108 ,  0.0265951 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}